#!/usr/bin/env python3
# E Minor v1.0 â€” Star-Code Validator and Compiler
# Performs AOT validations on the AST produced by eminor_parser.py
# and compiles valid E Minor programs

import sys, json, os, argparse, re, struct, tempfile, subprocess
from typing import List, Dict, Any, Optional, Tuple, Set, Union
from enum import Enum, auto
from dataclasses import dataclass, field

def _walk(node, fn):
    if isinstance(node, dict):
        fn(node)
        for k, v in node.items():
            if isinstance(v, (dict, list)):
                _walk(v, fn)
    elif isinstance(node, list):
        for x in node: _walk(x, fn)

SEVERITY = {"ERROR":"ERROR","WARN":"WARN","INFO":"INFO"}

def validate(ast: Dict[str, Any]) -> List[Dict[str, Any]]:
    issues: List[Dict[str, Any]] = []
    declared_caps = set()   # from LetDecl
    inited_caps   = set()   # after InitStmt
    leased_caps   = set()   # after Lease/Sublease/Release
    labels        = set()   # defined labels
    gotos         = []      # (label, line, col)

    # First pass: collect labels and lets
    def pass1(n):
        if n.get("_type") == "LetDecl":
            name = n["name"]["name"]
            declared_caps.add(name)
        elif n.get("_type") == "LabelStmt":
            labels.add(n["name"])

    _walk(ast, pass1)

    def report(kind, msg, line, col, code):
        issues.append({"severity":kind,"code":code,"message":msg,"line":line,"column":col})

    # Second pass: validations
    def pass2(n):
        t = n.get("_type")
        if t == "InitStmt":
            name = n["target"]["name"]
            inited_caps.add(name)
        elif t in ("LoadStmt","RenderStmt","InputStmt","OutputStmt","StampStmt","ExpireStmt"):
            name = n["target"]["name"]
            if name not in inited_caps and name not in declared_caps:
                report(SEVERITY["WARN"], f"Capsule ${name} used before init/let", n["line"], n["column"], "SC001")
        elif t in ("SendStmt","RecvStmt"):
            a = n["chan"]["name"]; b = n["pkt"]["name"]
            if a not in inited_caps and a not in declared_caps:
                report(SEVERITY["WARN"], f"Channel ${a} used before init/let", n["line"], n["column"], "SC002")
            if b not in inited_caps and b not in declared_caps:
                report(SEVERITY["WARN"], f"Packet ${b} used before init/let", n["line"], n["column"], "SC003")
        elif t == "LeaseStmt":
            nm = n["target"]["name"]
            if nm in leased_caps:
                report(SEVERITY["ERROR"], f"Capsule ${nm} double-lease without release", n["line"], n["column"], "SC010")
            leased_caps.add(nm)
        elif t in ("SubleaseStmt",):
            nm = n["target"]["name"]
            if nm not in leased_caps:
                report(SEVERITY["WARN"], f"Sublease on non-leased capsule ${nm}", n["line"], n["column"], "SC011")
        elif t == "ReleaseStmt":
            nm = n["target"]["name"]
            if nm not in leased_caps:
                report(SEVERITY["WARN"], f"Release on non-leased capsule ${nm}", n["line"], n["column"], "SC012")
            leased_caps.discard(nm)
        elif t == "SleepStmt":
            # duration must be integer nanoseconds
            dur = n["duration"]["value"]
            if not isinstance(dur, int) or dur < 0:
                report(SEVERITY["ERROR"], "Sleep duration must be non-negative integer nanoseconds", n["line"], n["column"], "SC020")
        elif t == "ExpireStmt":
            dur = n["duration"]["value"]
            if not isinstance(dur, int) or dur < 0:
                report(SEVERITY["ERROR"], "Expire duration must be non-negative integer nanoseconds", n["line"], n["column"], "SC021")
        elif t == "GotoStmt":
            gotos.append((n["label"], n["line"], n["column"]))
        elif t == "IfStmt":
            # shallow type-ish check: cond should be literal bool or an expression (assume ok); warn if literal non-bool
            c = n["cond"]
            if c.get("_type") == "Literal" and c.get("kind") != "BOOL":
                report(SEVERITY["WARN"], "Non-boolean literal used as condition", n["line"], n["column"], "SC030")

    _walk(ast, pass2)

    # Post: check gotos
    for label, line, col in gotos:
        if label not in labels:
            report(SEVERITY["ERROR"], f"goto :{label} targets undefined label", line, col, "SC040")

    return issues

def main():
    import argparse
    ap = argparse.ArgumentParser(description="E Minor Star-Code Validator")
    ap.add_argument("ast_json", help="Path to AST JSON file generated by eminor_parser.py")
    args = ap.parse_args()
    with open(args.ast_json, "r", encoding="utf-8") as f:
        ast = json.load(f)
    issues = validate(ast)
    print(json.dumps({"issues": issues}, indent=2))

# ========================= E Minor Compiler =========================
# The following code extends the validator to create a complete compiler

# ---- Language definition constants ----
KEYWORDS = {
    'initialize', 'capsule', 'assign', 'value', 'to', 'invoke', 'function', 'with',
    'terminate', 'execution', 'if', 'else', 'loop', 'goto', 'let', 'worker',
    'u8', 'u16', 'u32', 'u64', 'i8', 'i16', 'i32', 'i64', 'f32', 'f64',
    'bool', 'stamp', 'duration', 'byte', 'true', 'false', 'main', 'entry_point',
    'module', 'export', 'import', 'ns', 'ms', 's', 'm', 'h'
}

# Time unit conversions to nanoseconds
TIME_UNITS = {
    'ns': 1,
    'ms': 1_000_000,
    's': 1_000_000_000,
    'm': 60 * 1_000_000_000,
    'h': 60 * 60 * 1_000_000_000
}

# Opcodes for IR generation
OPCODES = {
    "NOP": 0x00,
    "INIT": 0x01,
    "LOAD": 0x02,
    "CALL": 0x03,
    "CALLA": 0x04,
    "EXIT": 0x05,
    
    "LEASE": 0x10,
    "SUBLEASE": 0x11,
    "RELEASE": 0x12,
    "CHECKEXP": 0x13,
    
    "RENDER": 0x20,
    "INPUT": 0x21,
    "OUTPUT": 0x22,
    
    "SEND": 0x30,
    "RECV": 0x31,
    
    "SPAWN": 0x40,
    "JOIN": 0x41,
    
    "STAMP": 0x50,
    "EXPIRE": 0x51,
    "SLEEP": 0x52,
    "YIELD": 0x53,
    
    "ERROR": 0x60,
    
    "PUSHK": 0x80,
    "PUSHCAP": 0x82,
    "UNOP": 0x90,
    "BINOP": 0x91,
    
    "JZ": 0xA0,
    "JNZ": 0xA1,
    "JMP": 0xA2,
    
    "END": 0xFF
}

# Binary operators and their codes
BINARY_OPS = {
    "||": 1, 
    "&&": 2,
    "==": 3, 
    "!=": 4,
    "<": 5, 
    ">": 6, 
    "<=": 7, 
    ">=": 8,
    "+": 9, 
    "-": 10, 
    "*": 11, 
    "/": 12, 
    "%": 13
}

# Unary operators and their codes
UNARY_OPS = {
    "!": 1, 
    "~": 2, 
    "u-": 3
}

class TokenType(Enum):
    # Keywords
    KW_INITIALIZE = auto()
    KW_CAPSULE = auto()
    KW_ASSIGN = auto()
    KW_VALUE = auto()
    KW_TO = auto()
    KW_INVOKE = auto()
    KW_FUNCTION = auto()
    KW_WITH = auto()
    KW_TERMINATE = auto()
    KW_EXECUTION = auto()
    KW_IF = auto()
    KW_ELSE = auto()
    KW_LOOP = auto()
    KW_GOTO = auto()
    KW_LET = auto()
    KW_WORKER = auto()
    KW_BYTE = auto()
    KW_TRUE = auto()
    KW_FALSE = auto()
    KW_MAIN = auto()
    KW_ENTRY_POINT = auto()
    KW_MODULE = auto()
    KW_EXPORT = auto()
    KW_IMPORT = auto()
    
    # Type names
    KW_U8 = auto()
    KW_U16 = auto()
    KW_U32 = auto()
    KW_U64 = auto()
    KW_I8 = auto()
    KW_I16 = auto()
    KW_I32 = auto()
    KW_I64 = auto()
    KW_F32 = auto()
    KW_F64 = auto()
    KW_BOOL = auto()
    KW_STAMP = auto()
    KW_DURATION = auto()
    
    # Time units
    KW_NS = auto()
    KW_MS = auto()
    KW_S = auto()
    KW_M = auto()
    KW_H = auto()
    
    # Directives
    AT_MAIN = auto()
    AT_ENTRY_POINT = auto()
    AT_MODULE = auto()
    AT_EXPORT = auto()
    AT_IMPORT = auto()
    
    # Hash directives
    HASH_INIT = auto()
    HASH_LOAD = auto()
    HASH_CALL = auto()
    HASH_EXIT = auto()
    HASH_LEASE = auto()
    HASH_SUBLEASE = auto()
    HASH_RELEASE = auto()
    HASH_CHECK_EXP = auto()
    HASH_RENDER = auto()
    HASH_INPUT = auto()
    HASH_OUTPUT = auto()
    HASH_SEND = auto()
    HASH_RECV = auto()
    HASH_SPAWN = auto()
    HASH_JOIN = auto()
    HASH_STAMP = auto()
    HASH_EXPIRE = auto()
    HASH_SLEEP = auto()
    HASH_YIELD = auto()
    HASH_ERROR = auto()
    HASH_IF = auto()
    HASH_ELSE = auto()
    HASH_ENDIF = auto()
    HASH_LOOP = auto()
    HASH_BREAK = auto()
    HASH_CONTINUE = auto()
    
    # Literals
    INT = auto()
    HEX = auto()
    FLOAT = auto()
    DURATION = auto()
    STRING = auto()
    BOOL = auto()
    
    # Identifiers
    IDENT = auto()
    DOLLAR_IDENT = auto()
    
    # Operators
    PLUS = auto()
    MINUS = auto()
    STAR = auto()
    SLASH = auto()
    PERCENT = auto()
    BANG = auto()
    TILDE = auto()
    EQ = auto()
    EQEQ = auto()
    BANGEQ = auto()
    LT = auto()
    GT = auto()
    LTE = auto()
    GTE = auto()
    ANDAND = auto()
    OROR = auto()
    AMP = auto()
    BAR = auto()
    CARET = auto()
    
    # Punctuation
    LPAREN = auto()
    RPAREN = auto()
    LBRACE = auto()
    RBRACE = auto()
    LBRACKET = auto()
    RBRACKET = auto()
    COMMA = auto()
    SEMICOLON = auto()
    COLON = auto()
    DOT = auto()
    HASH = auto()
    AT = auto()
    
    # Special
    EOF = auto()
    ERROR = auto()

class Token:
    def __init__(self, type: TokenType, lexeme: str, line: int, column: int, value=None):
        self.type = type
        self.lexeme = lexeme
        self.line = line
        self.column = column
        self.value = value
    
    def __repr__(self):
        if self.value is None:
            return f"{self.type.name}({self.lexeme}) at {self.line}:{self.column}"
        return f"{self.type.name}({self.lexeme}:{self.value}) at {self.line}:{self.column}"

class LexerError(Exception):
    pass

class Lexer:
    def __init__(self, source: str):
        self.source = source
        self.pos = 0
        self.line = 1
        self.column = 1
        self.current_char = self.source[0] if source else None
        
        # Build keyword and directive maps
        self.keywords = {}
        for kw in KEYWORDS:
            self.keywords[kw] = getattr(TokenType, f"KW_{kw.upper()}", TokenType.IDENT)
        
        # Hash directives
        self.hash_directives = {
            "init": TokenType.HASH_INIT,
            "load": TokenType.HASH_LOAD,
            "call": TokenType.HASH_CALL,
            "exit": TokenType.HASH_EXIT,
            "lease": TokenType.HASH_LEASE,
            "sublease": TokenType.HASH_SUBLEASE,
            "release": TokenType.HASH_RELEASE,
            "check_exp": TokenType.HASH_CHECK_EXP,
            "render": TokenType.HASH_RENDER,
            "input": TokenType.HASH_INPUT,
            "output": TokenType.HASH_OUTPUT,
            "send": TokenType.HASH_SEND,
            "recv": TokenType.HASH_RECV,
            "spawn": TokenType.HASH_SPAWN,
            "join": TokenType.HASH_JOIN,
            "stamp": TokenType.HASH_STAMP,
            "expire": TokenType.HASH_EXPIRE,
            "sleep": TokenType.HASH_SLEEP,
            "yield": TokenType.HASH_YIELD,
            "error": TokenType.HASH_ERROR,
            "if": TokenType.HASH_IF,
            "else": TokenType.HASH_ELSE,
            "endif": TokenType.HASH_ENDIF,
            "loop": TokenType.HASH_LOOP,
            "break": TokenType.HASH_BREAK,
            "continue": TokenType.HASH_CONTINUE
        }
        
        # At directives
        self.at_directives = {
            "main": TokenType.AT_MAIN,
            "entry_point": TokenType.AT_ENTRY_POINT,
            "module": TokenType.AT_MODULE,
            "export": TokenType.AT_EXPORT,
            "import": TokenType.AT_IMPORT
        }
    
    def advance(self):
        if self.current_char == '\n':
            self.line += 1
            self.column = 1
        else:
            self.column += 1
            
        self.pos += 1
        if self.pos >= len(self.source):
            self.current_char = None
        else:
            self.current_char = self.source[self.pos]
    
    def skip_whitespace(self):
        while self.current_char and self.current_char.isspace():
            self.advance()
    
    def skip_comment(self):
        if self.current_char == '/' and self.peek() == '/':
            self.advance()  # Skip first /
            self.advance()  # Skip second /
            
            # Skip until end of line
            while self.current_char and self.current_char != '\n':
                self.advance()
            
            # Skip newline character
            if self.current_char:
                self.advance()
        elif self.current_char == '/' and self.peek() == '*':
            self.advance()  # Skip /
            self.advance()  # Skip *
            
            # Skip until end of block comment
            while self.current_char:
                if self.current_char == '*' and self.peek() == '/':
                    self.advance()  # Skip *
                    self.advance()  # Skip /
                    break
                self.advance()
    
    def peek(self, offset=1):
        peek_pos = self.pos + offset
        if peek_pos >= len(self.source):
            return None
        return self.source[peek_pos]
    
    def tokenize(self):
        tokens = []
        
        # Initialize current character
        if not self.source:
            return tokens
        
        while self.current_char:
            # Skip whitespace and comments
            if self.current_char.isspace():
                self.skip_whitespace()
                continue
                
            if self.current_char == '/' and (self.peek() == '/' or self.peek() == '*'):
                self.skip_comment()
                continue
                
            # Handle identifiers and keywords
            if self.current_char.isalpha() or self.current_char == '_':
                tokens.append(self.identifier())
                continue
                
            # Handle dollar identifiers
            if self.current_char == '$':
                tokens.append(self.dollar_identifier())
                continue
                
            # Handle numbers
            if self.current_char.isdigit():
                tokens.append(self.number())
                continue
                
            # Handle strings
            if self.current_char == '"':
                tokens.append(self.string())
                continue
                
            # Handle hash directives
            if self.current_char == '#':
                tokens.append(self.hash_directive())
                continue
                
            # Handle at directives
            if self.current_char == '@':
                tokens.append(self.at_directive())
                continue
                
            # Handle operators and punctuation
            token = self.operator()
            if token:
                tokens.append(token)
                continue
                
            # If we get here, we encountered an unknown character
            raise LexerError(f"Unexpected character '{self.current_char}' at {self.line}:{self.column}")
        
        return tokens
    
    def identifier(self):
        """Parse an identifier or keyword."""
        line, column = self.line, self.column
        lexeme = ""
        
        while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):
            lexeme += self.current_char
            self.advance()
        
        # Check if this is a keyword
        if lexeme in self.keywords:
            token_type = self.keywords[lexeme]
            # Special handling for boolean literals
            if token_type == TokenType.KW_TRUE:
                return Token(TokenType.BOOL, lexeme, line, column, True)
            elif token_type == TokenType.KW_FALSE:
                return Token(TokenType.BOOL, lexeme, line, column, False)
            return Token(token_type, lexeme, line, column)
        
        # Regular identifier
        return Token(TokenType.IDENT, lexeme, line, column)
    
    def dollar_identifier(self):
        """Parse a dollar-prefixed identifier."""
        line, column = self.line, self.column
        self.advance()  # Skip $
        
        if not self.current_char or not (self.current_char.isalpha() or self.current_char == '_'):
            raise LexerError(f"Expected identifier after $ at {line}:{column}")
        
        name = ""
        while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):
            name += self.current_char
            self.advance()
        
        return Token(TokenType.DOLLAR_IDENT, f"${name}", line, column, name)
    
    def number(self):
        """Parse numeric literals: integers, hex, floats, or durations."""
        line, column = self.line, self.column
        
        # Check for hex
        if self.current_char == '0' and self.peek() and self.peek().lower() == 'x':
            return self.hex_number(line, column)
        
        # Parse the number part
        num_str = ""
        is_float = False
        
        while self.current_char and self.current_char.isdigit():
            num_str += self.current_char
            self.advance()
        
        # Check for decimal point (float)
        if self.current_char == '.':
            is_float = True
            num_str += self.current_char
            self.advance()
            
            # Must have at least one digit after decimal point
            if not self.current_char or not self.current_char.isdigit():
                raise LexerError(f"Expected digit after decimal point at {self.line}:{self.column}")
            
            while self.current_char and self.current_char.isdigit():
                num_str += self.current_char
                self.advance()
        
        # Check for duration suffix
        if self.current_char and self.current_char.isalpha():
            unit = ""
            
            # Get unit characters
            if self.current_char == 'n' and self.peek() == 's':
                unit = "ns"
                self.advance()
                self.advance()
            elif self.current_char == 'm' and self.peek() == 's':
                unit = "ms"
                self.advance()
                self.advance()
            elif self.current_char in ['s', 'm', 'h']:
                unit = self.current_char
                self.advance()
            
            if unit:
                # It's a duration
                if is_float:
                    base_value = float(num_str)
                else:
                    base_value = int(num_str)
                    
                # Convert to nanoseconds
                ns_value = int(base_value * TIME_UNITS[unit])
                return Token(TokenType.DURATION, f"{num_str}{unit}", line, column, ns_value)
        
        # Regular number
        if is_float:
            return Token(TokenType.FLOAT, num_str, line, column, float(num_str))
        else:
            return Token(TokenType.INT, num_str, line, column, int(num_str))
    
    def hex_number(self, line, column):
        """Parse a hexadecimal number."""
        lexeme = "0"
        self.advance()  # Skip '0'
        
        lexeme += self.current_char  # Add 'x'
        self.advance()  # Skip 'x'
        
        if not self.current_char or not self.current_char.lower() in "0123456789abcdef":
            raise LexerError(f"Expected hex digit after 0x at {self.line}:{self.column}")
        
        while self.current_char and self.current_char.lower() in "0123456789abcdef":
            lexeme += self.current_char
            self.advance()
        
        value = int(lexeme, 16)
        return Token(TokenType.HEX, lexeme, line, column, value)
    
    def string(self):
        """Parse a string literal."""
        line, column = self.line, self.column
        self.advance()  # Skip opening quote
        
        value = ""
        while self.current_char and self.current_char != '"':
            if self.current_char == '\\':
                self.advance()  # Skip backslash
                
                if not self.current_char:
                    raise LexerError(f"Unterminated string escape at {self.line}:{self.column}")
                
                # Handle escape sequences
                if self.current_char == 'n':
                    value += '\n'
                elif self.current_char == 't':
                    value += '\t'
                elif self.current_char == 'r':
                    value += '\r'
                elif self.current_char == '"':
                    value += '"'
                elif self.current_char == '\\':
                    value += '\\'
                elif self.current_char == 'x':
                    # Hex escape \xHH
                    if not self.peek() or not self.peek(2) or not (self.peek().lower() in "0123456789abcdef" and self.peek(2).lower() in "0123456789abcdef"):
                        raise LexerError(f"Invalid hex escape sequence at {self.line}:{self.column}")
                    
                    self.advance()  # Skip 'x'
                    hex_val = self.current_char + self.peek()
                    value += chr(int(hex_val, 16))
                    self.advance()  # Skip first hex digit
                else:
                    raise LexerError(f"Invalid escape sequence '\\{self.current_char}' at {self.line}:{self.column}")
            else:
                value += self.current_char
            
            self.advance()
        
        if not self.current_char:
            raise LexerError(f"Unterminated string starting at {line}:{column}")
        
        self.advance()  # Skip closing quote
        return Token(TokenType.STRING, f'"{value}"', line, column, value)
    
    def hash_directive(self):
        """Parse a hash directive."""
        line, column = self.line, self.column
        self.advance()  # Skip #
        
        # Get directive name
        name = ""
        while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):
            name += self.current_char
            self.advance()
        
        if not name:
            return Token(TokenType.HASH, "#", line, column)
        
        # Check if this is a known directive
        if name in self.hash_directives:
            return Token(self.hash_directives[name], f"#{name}", line, column)
        
        raise LexerError(f"Unknown hash directive '#{name}' at {line}:{column}")
    
    def at_directive(self):
        """Parse an at directive."""
        line, column = self.line, self.column
        self.advance()  # Skip @
        
        # Get directive name
        name = ""
        while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):
            name += self.current_char
            self.advance()
        
        if not name:
            return Token(TokenType.AT, "@", line, column)
        
        # Check if this is a known directive
        if name in self.at_directives:
            return Token(self.at_directives[name], f"@{name}", line, column)
        
        raise LexerError(f"Unknown at directive '@{name}' at {line}:{column}")
    
    def operator(self):
        """Parse operators and punctuation."""
        line, column = self.line, self.column
        
        # Single-character operators and punctuation
        if self.current_char == '+':
            self.advance()
            return Token(TokenType.PLUS, "+", line, column)
        elif self.current_char == '-':
            self.advance()
            return Token(TokenType.MINUS, "-", line, column)
        elif self.current_char == '*':
            self.advance()
            return Token(TokenType.STAR, "*", line, column)
        elif self.current_char == '/':
            self.advance()
            return Token(TokenType.SLASH, "/", line, column)
        elif self.current_char == '%':
            self.advance()
            return Token(TokenType.PERCENT, "%", line, column)
        elif self.current_char == '~':
            self.advance()
            return Token(TokenType.TILDE, "~", line, column)
        elif self.current_char == '(':
            self.advance()
            return Token(TokenType.LPAREN, "(", line, column)
        elif self.current_char == ')':
            self.advance()
            return Token(TokenType.RPAREN, ")", line, column)
        elif self.current_char == '{':
            self.advance()
            return Token(TokenType.LBRACE, "{", line, column)
        elif self.current_char == '}':
            self.advance()
            return Token(TokenType.RBRACE, "}", line, column)
        elif self.current_char == '[':
            self.advance()
            return Token(TokenType.LBRACKET, "[", line, column)
        elif self.current_char == ']':
            self.advance()
            return Token(TokenType.RBRACKET, "]", line, column)
        elif self.current_char == ',':
            self.advance()
            return Token(TokenType.COMMA, ",", line, column)
        elif self.current_char == ';':
            self.advance()
            return Token(TokenType.SEMICOLON, ";", line, column)
        elif self.current_char == ':':
            self.advance()
            return Token(TokenType.COLON, ":", line, column)
        elif self.current_char == '.':
            self.advance()
            return Token(TokenType.DOT, ".", line, column)
        elif self.current_char == '^':
            self.advance()
            return Token(TokenType.CARET, "^", line, column)
        
        # Two-character operators
        elif self.current_char == '=':
            self.advance()
            if self.current_char == '=':
                self.advance()
                return Token(TokenType.EQEQ, "==", line, column)
            return Token(TokenType.EQ, "=", line, column)
        elif self.current_char == '!':
            self.advance()
            if self.current_char == '=':
                self.advance()
                return Token(TokenType.BANGEQ, "!=", line, column)
            return Token(TokenType.BANG, "!", line, column)
        elif self.current_char == '<':
            self.advance()
            if self.current_char == '=':
                self.advance()
                return Token(TokenType.LTE, "<=", line, column)
            return Token(TokenType.LT, "<", line, column)
        elif self.current_char == '>':
            self.advance()
            if self.current_char == '=':
                self.advance()
                return Token(TokenType.GTE, ">=", line, column)
            return Token(TokenType.GT, ">", line, column)
        elif self.current_char == '&':
            self.advance()
            if self.current_char == '&':
                self.advance()
                return Token(TokenType.ANDAND, "&&", line, column)
            return Token(TokenType.AMP, "&", line, column)
        elif self.current_char == '|':
            self.advance()
            if self.current_char == '|':
                self.advance()
                return Token(TokenType.OROR, "||", line, column)
            return Token(TokenType.BAR, "|", line, column)
        
        return None

# ---- AST Node definitions ----
@dataclass
class Node:
    line: int
    column: int

@dataclass
class Expr(Node):
    pass

@dataclass
class Literal(Expr):
    kind: str
    value: Any

@dataclass
class Identifier(Expr):
    name: str
    is_dollar: bool = False

@dataclass
class UnaryOp(Expr):
    op: str
    rhs: Expr

@dataclass
class BinaryOp(Expr):
    op: str
    lhs: Expr
    rhs: Expr

@dataclass
class Program(Node):
    entry: 'EntryBlock'
    items: List[Union['Decl', 'Stmt']] = field(default_factory=list)

@dataclass
class EntryBlock(Node):
    kind: str
    block: 'Block'

@dataclass
class Block(Node):
    items: List[Union['Decl', 'Stmt']]

@dataclass
class Decl(Node):
    pass

@dataclass
class FunctionDecl(Decl):
    name: Identifier
    params: List['Param']
    return_type: Optional['TypeRef']
    body: Block

@dataclass
class WorkerDecl(Decl):
    name: Identifier
    params: List['Param']
    body: Block

@dataclass
class LetDecl(Decl):
    name: Identifier
    type_ref: 'TypeRef'

@dataclass
class ModuleDecl(Decl):
    path: str

@dataclass
class ExportDecl(Decl):
    symbol: Identifier

@dataclass
class ImportDecl(Decl):
    path: str
    alias: Optional[Identifier]

@dataclass
class Param(Node):
    name: Identifier
    type_ref: 'TypeRef'

@dataclass
class TypeRef(Node):
    kind: str
    name: Optional[str] = None
    inner: Optional['TypeRef'] = None
    size: Optional[int] = None

@dataclass
class Stmt(Node):
    pass

@dataclass
class InitStmt(Stmt):
    target: Identifier

@dataclass
class LoadStmt(Stmt):
    target: Identifier
    value: Expr

@dataclass
class CallStmt(Stmt):
    func: Identifier
    arg: Optional[Identifier] = None

@dataclass
class ExitStmt(Stmt):
    pass

@dataclass
class LeaseStmt(Stmt):
    target: Identifier

@dataclass
class SubleaseStmt(Stmt):
    target: Identifier

@dataclass
class ReleaseStmt(Stmt):
    target: Identifier

@dataclass
class CheckExpStmt(Stmt):
    target: Identifier

@dataclass
class RenderStmt(Stmt):
    target: Identifier

@dataclass
class InputStmt(Stmt):
    target: Identifier

@dataclass
class OutputStmt(Stmt):
    target: Identifier

@dataclass
class SendStmt(Stmt):
    chan: Identifier
    pkt: Identifier

@dataclass
class RecvStmt(Stmt):
    chan: Identifier
    pkt: Identifier

@dataclass
class SpawnStmt(Stmt):
    func: Identifier
    args: List[Union[Expr, Identifier]]

@dataclass
class JoinStmt(Stmt):
    thread: Identifier

@dataclass
class StampStmt(Stmt):
    target: Identifier
    value: Expr

@dataclass
class ExpireStmt(Stmt):
    target: Identifier
    duration: Literal

@dataclass
class SleepStmt(Stmt):
    duration: Literal

@dataclass
class YieldStmt(Stmt):
    pass

@dataclass
class ErrorStmt(Stmt):
    target: Identifier
    code: Expr
    message: Literal

@dataclass
class IfStmt(Stmt):
    cond: Expr
    then_block: Block
    else_block: Optional[Block] = None

@dataclass
class LoopStmt(Stmt):
    cond: Expr
    body: Block

@dataclass
class BreakStmt(Stmt):
    pass

@dataclass
class ContinueStmt(Stmt):
    pass

@dataclass
class GotoStmt(Stmt):
    label: str

@dataclass
class LabelStmt(Stmt):
    name: str

class ParserError(Exception):
    pass

class Parser:
    def __init__(self, tokens: List[Token]):
        self.tokens = tokens
        self.current = 0
    
    def is_at_end(self):
        return self.current >= len(self.tokens)
    
    def peek(self):
        if self.is_at_end():
            return None
        return self.tokens[self.current]
    
    def previous(self):
        return self.tokens[self.current - 1]
    
    def advance(self):
        if not self.is_at_end():
            self.current += 1
        return self.previous()
    
    def match(self, *types):
        for type in types:
            if self.check(type):
                self.advance()
                return True
        return False
    
    def check(self, type):
        if self.is_at_end():
            return False
        return self.peek().type == type
    
    def consume(self, type, message):
        if self.check(type):
            return self.advance()
        
        token = self.peek()
        raise ParserError(f"{message} at {token.line}:{token.column}")
    
    def parse(self):
        """Parse a complete E Minor program."""
        entry = self.parse_entry_block()
        items = []
        
        while not self.is_at_end():
            token = self.peek()
            
            # Parse declarations
            if token.type in (TokenType.KW_FUNCTION, TokenType.KW_WORKER, TokenType.KW_LET,
                            TokenType.AT_MODULE, TokenType.AT_EXPORT, TokenType.AT_IMPORT):
                items.append(self.parse_declaration())
            else:
                # Parse statements
                items.append(self.parse_statement())
        
        return Program(line=entry.line, column=entry.column, entry=entry, items=items)
    
    def parse_entry_block(self):
        """Parse the program entry block (@main or @entry_point)."""
        token = self.consume(TokenType.AT_MAIN, "Expected @main or @entry_point")
        
        # Parse the block
        block = self.parse_block()
        
        return EntryBlock(line=token.line, column=token.column, kind=token.type.name, block=block)
    
    def parse_block(self):
        """Parse a block of statements."""
        open_brace = self.consume(TokenType.LBRACE, "Expected '{'")
        items = []
        
        while not self.check(TokenType.RBRACE) and not self.is_at_end():
            token = self.peek()
            
            # Parse declarations inside the block
            if token.type in (TokenType.KW_FUNCTION, TokenType.KW_WORKER, TokenType.KW_LET,
                            TokenType.AT_MODULE, TokenType.AT_EXPORT, TokenType.AT_IMPORT):
                items.append(self.parse_declaration())
            else:
                # Parse statements
                items.append(self.parse_statement())
        
        self.consume(TokenType.RBRACE, "Expected '}'")
        
        return Block(line=open_brace.line, column=open_brace.column, items=items)
    
    def parse_declaration(self):
        """Parse various declarations."""
        token = self.peek()
        
        if token.type == TokenType.KW_FUNCTION:
            return self.parse_function_declaration()
        elif token.type == TokenType.KW_WORKER:
            return self.parse_worker_declaration()
        elif token.type == TokenType.KW_LET:
            return self.parse_let_declaration()
        elif token.type == TokenType.AT_MODULE:
            return self.parse_module_declaration()
        elif token.type == TokenType.AT_EXPORT:
            return self.parse_export_declaration()
        elif token.type == TokenType.AT_IMPORT:
            return self.parse_import_declaration()
        
        raise ParserError(f"Unexpected token {token.type.name} at {token.line}:{token.column}")
    
    def parse_function_declaration(self):
        """Parse a function declaration."""
        keyword = self.consume(TokenType.KW_FUNCTION, "Expected 'function'")
        
        # Parse function name
        name = self.parse_dollar_identifier()
        
        # Parse parameters
        self.consume(TokenType.LPAREN, "Expected '(' after function name")
        params = []
        
        if not self.check(TokenType.RPAREN):
            params.append(self.parse_parameter())
            
            while self.match(TokenType.COMMA):
                params.append(self.parse_parameter())
        
        self.consume(TokenType.RPAREN, "Expected ')' after parameters")
        
        # Parse optional return type
        return_type = None
        if self.match(TokenType.COLON):
            return_type = self.parse_type()
        
        # Parse function body
        body = self.parse_block()
        
        return FunctionDecl(
            line=keyword.line,
            column=keyword.column,
            name=name,
            params=params,
            return_type=return_type,
            body=body
        )
    
    def parse_worker_declaration(self):
        """Parse a worker declaration."""
        keyword = self.consume(TokenType.KW_WORKER, "Expected 'worker'")
        
        # Parse worker name
        name = self.parse_dollar_identifier()
        
        # Parse parameters
        self.consume(TokenType.LPAREN, "Expected '(' after worker name")
        params = []
        
        if not self.check(TokenType.RPAREN):
            params.append(self.parse_parameter())
            
            while self.match(TokenType.COMMA):
                params.append(self.parse_parameter())
        
        self.consume(TokenType.RPAREN, "Expected ')' after parameters")
        
        # Parse worker body
        body = self.parse_block()
        
        return WorkerDecl(
            line=keyword.line,
            column=keyword.column,
            name=name,
            params=params,
            body=body
        )
    
    def parse_parameter(self):
        """Parse a function/worker parameter."""
        name = self.parse_dollar_identifier()
        
        self.consume(TokenType.COLON, "Expected ':' after parameter name")
        type_ref = self.parse_type()
        
        return Param(
            line=name.line,
            column=name.column,
            name=name,
            type_ref=type_ref
        )
    
    def parse_let_declaration(self):
        """Parse a let declaration."""
        keyword = self.consume(TokenType.KW_LET, "Expected 'let'")
        
        # Parse variable name
        name = self.parse_dollar_identifier()
        
        # Parse type
        self.consume(TokenType.COLON, "Expected ':' after variable name")
        type_ref = self.parse_type()
        
        self.consume(TokenType.SEMICOLON, "Expected ';' after let declaration")
        
        return LetDecl(
            line=keyword.line,
            column=keyword.column,
            name=name,
            type_ref=type_ref
        )
    
    def parse_module_declaration(self):
        """Parse a module declaration."""
        at_module = self.consume(TokenType.AT_MODULE, "Expected '@module'")
        
        # Parse module path
        path = self.consume(TokenType.STRING, "Expected string literal for module path").value
        
        return ModuleDecl(
            line=at_module.line,
            column=at_module.column,
            path=path
        )
    
    def parse_export_declaration(self):
        """Parse an export declaration."""
        at_export = self.consume(TokenType.AT_EXPORT, "Expected '@export'")
        
        # Skip optional 'function' keyword
        self.match(TokenType.KW_FUNCTION)
        
        # Parse symbol to export
        symbol = self.parse_dollar_identifier()
        
        return ExportDecl(
            line=at_export.line,
            column=at_export.column,
            symbol=symbol
        )
    
    def parse_import_declaration(self):
        """Parse an import declaration."""
        at_import = self.consume(TokenType.AT_IMPORT, "Expected '@import'")
        
        # Parse import path
        path = self.consume(TokenType.STRING, "Expected string literal for import path").value
        
        # Parse optional alias
        alias = None
        if self.match(TokenType.IDENT) and self.previous().lexeme == "as":
            alias = self.parse_dollar_identifier()
        
        return ImportDecl(
            line=at_import.line,
            column=at_import.column,
            path=path,
            alias=alias
        )
    
    def parse_type(self):
        """Parse a type reference."""
        token = self.peek()
        
        # Handle byte array type
        if token.type == TokenType.KW_BYTE:
            byte_token = self.advance()
            self.consume(TokenType.LBRACKET, "Expected '[' after 'byte'")
            size = self.consume(TokenType.INT, "Expected integer size for byte array").value
            self.consume(TokenType.RBRACKET, "Expected ']' after byte array size")
            
            return TypeRef(
                line=byte_token.line,
                column=byte_token.column,
                kind="byte_array",
                size=size
            )
        
        # Handle capsule/packet types
        if token.type in (TokenType.KW_CAPSULE, TokenType.IDENT) and token.lexeme in ("capsule", "packet"):
            head_token = self.advance()
            kind = head_token.lexeme
            
            self.consume(TokenType.LT, "Expected '<' after capsule/packet")
            inner = self.parse_type()
            self.consume(TokenType.GT, "Expected '>' after inner type")
            
            return TypeRef(
                line=head_token.line,
                column=head_token.column,
                kind=kind,
                inner=inner
            )
        
        # Handle primitive types
        if token.type in (
            TokenType.KW_U8, TokenType.KW_U16, TokenType.KW_U32, TokenType.KW_U64,
            TokenType.KW_I8, TokenType.KW_I16, TokenType.KW_I32, TokenType.KW_I64,
            TokenType.KW_F32, TokenType.KW_F64, TokenType.KW_BOOL, TokenType.KW_STAMP, TokenType.KW_DURATION
        ):
            prim_token = self.advance()
            
            return TypeRef(
                line=prim_token.line,
                column=prim_token.column,
                kind="prim",
                name=prim_token.lexeme
            )
        
        raise ParserError(f"Expected type but got {token.type.name} at {token.line}:{token.column}")
    
    def parse_dollar_identifier(self):
        """Parse a dollar-prefixed identifier."""
        token = self.consume(TokenType.DOLLAR_IDENT, "Expected $identifier")
        
        return Identifier(
            line=token.line,
            column=token.column,
            name=token.value,
            is_dollar=True
        )
    
    def parse_statement(self):
        """Parse a statement."""
        token = self.peek()
        
        # Label statement
        if token.type == TokenType.COLON:
            colon = self.advance()
            name = self.consume(TokenType.IDENT, "Expected identifier after ':'").lexeme
            
            return LabelStmt(
                line=colon.line,
                column=colon.column,
                name=name
            )
        
        # Hash directives
        if token.type == TokenType.HASH_INIT:
            return self.parse_init_stmt()
        elif token.type == TokenType.HASH_LOAD:
            return self.parse_load_stmt()
        elif token.type == TokenType.HASH_CALL:
            return self.parse_call_stmt()
        elif token.type == TokenType.HASH_EXIT:
            return self.parse_exit_stmt()
        elif token.type == TokenType.HASH_LEASE:
            return self.parse_lease_stmt()
        elif token.type == TokenType.HASH_SUBLEASE:
            return self.parse_sublease_stmt()
        elif token.type == TokenType.HASH_RELEASE:
            return self.parse_release_stmt()
        elif token.type == TokenType.HASH_CHECK_EXP:
            return self.parse_check_exp_stmt()
        elif token.type == TokenType.HASH_RENDER:
            return self.parse_render_stmt()
        elif token.type == TokenType.HASH_INPUT:
            return self.parse_input_stmt()
        elif token.type == TokenType.HASH_OUTPUT:
            return self.parse_output_stmt()
        elif token.type == TokenType.HASH_SEND:
            return self.parse_send_stmt()
        elif token.type == TokenType.HASH_RECV:
            return self.parse_recv_stmt()
        elif token.type == TokenType.HASH_SPAWN:
            return self.parse_spawn_stmt()
        elif token.type == TokenType.HASH_JOIN:
            return self.parse_join_stmt()
        elif token.type == TokenType.HASH_STAMP:
            return self.parse_stamp_stmt()
        elif token.type == TokenType.HASH_EXPIRE:
            return self.parse_expire_stmt()
        elif token.type == TokenType.HASH_SLEEP:
            return self.parse_sleep_stmt()
        elif token.type == TokenType.HASH_YIELD:
            return self.parse_yield_stmt()
        elif token.type == TokenType.HASH_ERROR:
            return self.parse_error_stmt()
        elif token.type == TokenType.HASH_IF:
            return self.parse_if_stmt()
        elif token.type == TokenType.HASH_LOOP:
            return self.parse_loop_stmt()
        elif token.type == TokenType.HASH_BREAK:
            return self.parse_break_stmt()
        elif token.type == TokenType.HASH_CONTINUE:
            return self.parse_continue_stmt()
        
        # Long-form statements
        elif token.type == TokenType.KW_INITIALIZE:
            return self.parse_longform_init_stmt()
        elif token.type == TokenType.KW_ASSIGN:
            return self.parse_longform_load_stmt()
        elif token.type == TokenType.KW_INVOKE:
            return self.parse_longform_call_stmt()
        elif token.type == TokenType.KW_TERMINATE:
            return self.parse_longform_exit_stmt()
        elif token.type == TokenType.KW_GOTO:
            return self.parse_goto_stmt()
        
        raise ParserError(f"Unexpected token {token.type.name} at {token.line}:{token.column}")
    
    def parse_init_stmt(self):
        """Parse #init statement."""
        directive = self.consume(TokenType.HASH_INIT, "Expected #init")
        target = self.parse_dollar_identifier()
        
        return InitStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_load_stmt(self):
        """Parse #load statement."""
        directive = self.consume(TokenType.HASH_LOAD, "Expected #load")
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after target in #load")
        value = self.parse_value_expr()
        
        return LoadStmt(
            line=directive.line,
            column=directive.column,
            target=target,
            value=value
        )
    
    def parse_call_stmt(self):
        """Parse #call statement."""
        directive = self.consume(TokenType.HASH_CALL, "Expected #call")
        func = self.parse_dollar_identifier()
        
        arg = None
        if self.match(TokenType.COMMA):
            arg = self.parse_dollar_identifier()
        
        return CallStmt(
            line=directive.line,
            column=directive.column,
            func=func,
            arg=arg
        )
    
    def parse_exit_stmt(self):
        """Parse #exit statement."""
        directive = self.consume(TokenType.HASH_EXIT, "Expected #exit")
        
        return ExitStmt(
            line=directive.line,
            column=directive.column
        )
    
    def parse_lease_stmt(self):
        """Parse #lease statement."""
        directive = self.consume(TokenType.HASH_LEASE, "Expected #lease")
        target = self.parse_dollar_identifier()
        
        return LeaseStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_sublease_stmt(self):
        """Parse #sublease statement."""
        directive = self.consume(TokenType.HASH_SUBLEASE, "Expected #sublease")
        target = self.parse_dollar_identifier()
        
        return SubleaseStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_release_stmt(self):
        """Parse #release statement."""
        directive = self.consume(TokenType.HASH_RELEASE, "Expected #release")
        target = self.parse_dollar_identifier()
        
        return ReleaseStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_check_exp_stmt(self):
        """Parse #check_exp statement."""
        directive = self.consume(TokenType.HASH_CHECK_EXP, "Expected #check_exp")
        target = self.parse_dollar_identifier()
        
        return CheckExpStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_render_stmt(self):
        """Parse #render statement."""
        directive = self.consume(TokenType.HASH_RENDER, "Expected #render")
        target = self.parse_dollar_identifier()
        
        return RenderStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_input_stmt(self):
        """Parse #input statement."""
        directive = self.consume(TokenType.HASH_INPUT, "Expected #input")
        target = self.parse_dollar_identifier()
        
        return InputStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_output_stmt(self):
        """Parse #output statement."""
        directive = self.consume(TokenType.HASH_OUTPUT, "Expected #output")
        target = self.parse_dollar_identifier()
        
        return OutputStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_send_stmt(self):
        """Parse #send statement."""
        directive = self.consume(TokenType.HASH_SEND, "Expected #send")
        chan = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after channel in #send")
        pkt = self.parse_dollar_identifier()
        
        return SendStmt(
            line=directive.line,
            column=directive.column,
            chan=chan,
            pkt=pkt
        )
    
    def parse_recv_stmt(self):
        """Parse #recv statement."""
        directive = self.consume(TokenType.HASH_RECV, "Expected #recv")
        chan = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after channel in #recv")
        pkt = self.parse_dollar_identifier()
        
        return RecvStmt(
            line=directive.line,
            column=directive.column,
            chan=chan,
            pkt=pkt
        )
    
    def parse_spawn_stmt(self):
        """Parse #spawn statement."""
        directive = self.consume(TokenType.HASH_SPAWN, "Expected #spawn")
        func = self.parse_dollar_identifier()
        
        args = []
        if self.match(TokenType.COMMA):
            args.append(self.parse_arg())
            
            while self.match(TokenType.COMMA):
                args.append(self.parse_arg())
        
        return SpawnStmt(
            line=directive.line,
            column=directive.column,
            func=func,
            args=args
        )
    
    def parse_arg(self):
        """Parse an argument for spawn."""
        token = self.peek()
        
        if token.type == TokenType.DOLLAR_IDENT:
            return self.parse_dollar_identifier()
        elif token.type in (TokenType.INT, TokenType.HEX, TokenType.FLOAT, TokenType.DURATION, TokenType.STRING, TokenType.BOOL):
            return self.parse_value_expr()
        
        return self.parse_expr()
    
    def parse_join_stmt(self):
        """Parse #join statement."""
        directive = self.consume(TokenType.HASH_JOIN, "Expected #join")
        thread = self.parse_dollar_identifier()
        
        return JoinStmt(
            line=directive.line,
            column=directive.column,
            thread=thread
        )
    
    def parse_stamp_stmt(self):
        """Parse #stamp statement."""
        directive = self.consume(TokenType.HASH_STAMP, "Expected #stamp")
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after target in #stamp")
        value = self.parse_value_expr()
        
        return StampStmt(
            line=directive.line,
            column=directive.column,
            target=target,
            value=value
        )
    
    def parse_expire_stmt(self):
        """Parse #expire statement."""
        directive = self.consume(TokenType.HASH_EXPIRE, "Expected #expire")
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after target in #expire")
        duration_token = self.consume(TokenType.DURATION, "Expected duration value")
        
        duration = Literal(
            line=duration_token.line,
            column=duration_token.column,
            kind="DURATION",
            value=duration_token.value
        )
        
        return ExpireStmt(
            line=directive.line,
            column=directive.column,
            target=target,
            duration=duration
        )
    
    def parse_sleep_stmt(self):
        """Parse #sleep statement."""
        directive = self.consume(TokenType.HASH_SLEEP, "Expected #sleep")
        duration_token = self.consume(TokenType.DURATION, "Expected duration value")
        
        duration = Literal(
            line=duration_token.line,
            column=duration_token.column,
            kind="DURATION",
            value=duration_token.value
        )
        
        return SleepStmt(
            line=directive.line,
            column=directive.column,
            duration=duration
        )
    
    def parse_yield_stmt(self):
        """Parse #yield statement."""
        directive = self.consume(TokenType.HASH_YIELD, "Expected #yield")
        
        return YieldStmt(
            line=directive.line,
            column=directive.column
        )
    
    def parse_error_stmt(self):
        """Parse #error statement."""
        directive = self.consume(TokenType.HASH_ERROR, "Expected #error")
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.COMMA, "Expected ',' after target in #error")
        code = self.parse_value_expr()
        
        self.consume(TokenType.COMMA, "Expected ',' after code in #error")
        msg_token = self.consume(TokenType.STRING, "Expected string message")
        
        message = Literal(
            line=msg_token.line,
            column=msg_token.column,
            kind="STRING",
            value=msg_token.value
        )
        
        return ErrorStmt(
            line=directive.line,
            column=directive.column,
            target=target,
            code=code,
            message=message
        )
    
    def parse_if_stmt(self):
        """Parse #if statement."""
        directive = self.consume(TokenType.HASH_IF, "Expected #if")
        
        self.consume(TokenType.LPAREN, "Expected '(' after #if")
        cond = self.parse_expr()
        self.consume(TokenType.RPAREN, "Expected ')' after condition")
        
        then_block = self.parse_block()
        
        else_block = None
        if self.match(TokenType.HASH_ELSE):
            else_block = self.parse_block()
        
        self.consume(TokenType.HASH_ENDIF, "Expected #endif after if statement")
        
        return IfStmt(
            line=directive.line,
            column=directive.column,
            cond=cond,
            then_block=then_block,
            else_block=else_block
        )
    
    def parse_loop_stmt(self):
        """Parse #loop statement."""
        directive = self.consume(TokenType.HASH_LOOP, "Expected #loop")
        
        self.consume(TokenType.LPAREN, "Expected '(' after #loop")
        cond = self.parse_expr()
        self.consume(TokenType.RPAREN, "Expected ')' after condition")
        
        body = self.parse_block()
        
        return LoopStmt(
            line=directive.line,
            column=directive.column,
            cond=cond,
            body=body
        )
    
    def parse_break_stmt(self):
        """Parse #break statement."""
        directive = self.consume(TokenType.HASH_BREAK, "Expected #break")
        
        return BreakStmt(
            line=directive.line,
            column=directive.column
        )
    
    def parse_continue_stmt(self):
        """Parse #continue statement."""
        directive = self.consume(TokenType.HASH_CONTINUE, "Expected #continue")
        
        return ContinueStmt(
            line=directive.line,
            column=directive.column
        )
    
    def parse_goto_stmt(self):
        """Parse #goto statement."""
        directive = self.consume(TokenType.KW_GOTO, "Expected 'goto'")
        
        target = self.consume(TokenType.IDENT, "Expected label name after goto")
        
        return GotoStmt(
            line=directive.line,
            column=directive.column,
            label=target.lexeme
        )
    
    def parse_longform_init_stmt(self):
        """Parse long-form initialize statement (initialize ... to ...)."""
        directive = self.consume(TokenType.KW_INITIALIZE, "Expected 'initialize'")
        
        # Parse capsule name
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.KW_TO, "Expected 'to' after initialize target")
        
        # Parse initial value
        value = self.parse_value_expr()
        
        self.consume(TokenType.SEMICOLON, "Expected ';' after long-form initialize")
        
        return InitStmt(
            line=directive.line,
            column=directive.column,
            target=target
        )
    
    def parse_longform_load_stmt(self):
        """Parse long-form load statement (assign ... value ...)."""
        directive = self.consume(TokenType.KW_ASSIGN, "Expected 'assign'")
        
        # Parse target capsule/packet
        target = self.parse_dollar_identifier()
        
        self.consume(TokenType.KW_VALUE, "Expected 'value' after assign target")
        
        # Parse value expression
        value = self.parse_value_expr()
        
        self.consume(TokenType.SEMICOLON, "Expected ';' after long-form load")
        
        return LoadStmt(
            line=directive.line,
            column=directive.column,
            target=target,
            value=value
        )
    
    def parse_longform_call_stmt(self):
        """Parse long-form call statement (invoke ... with ...)."""
        directive = self.consume(TokenType.KW_INVOKE, "Expected 'invoke'")
        
        # Parse function name
        func = self.parse_dollar_identifier()
        
        args = []
        if self.match(TokenType.KW_WITH):
            self.consume(TokenType.LPAREN, "Expected '(' after with")
            
            if not self.check(TokenType.RPAREN):
                args.append(self.parse_arg())
                
                while self.match(TokenType.COMMA):
                    args.append(self.parse_arg())
            
            self.consume(TokenType.RPAREN, "Expected ')' after arguments")
        
        self.consume(TokenType.SEMICOLON, "Expected ';' after long-form call")
        
        return CallStmt(
            line=directive.line,
            column=directive.column,
            func=func,
            args=args
        )
    
    def parse_longform_exit_stmt(self):
        """Parse long-form exit statement (terminate ...)."""
        directive = self.consume(TokenType.KW_TERMINATE, "Expected 'terminate'")
        
        args = []
        if not self.check(TokenType.SEMICOLON):
            args.append(self.parse_value_expr())
            
            while self.match(TokenType.COMMA):
                args.append(self.parse_value_expr())
        
        self.consume(TokenType.SEMICOLON, "Expected ';' after long-form terminate")
        
        return ExitStmt(
            line=directive.line,
            column=directive.column
        )
    
    def parse_value_expr(self):
        """Parse a value expression (literal, identifier, or expression)."""
        token = self.peek()
        
        if token.type in (TokenType.INT, TokenType.HEX, TokenType.FLOAT, TokenType.DURATION, TokenType.STRING, TokenType.BOOL):
            t = self.advance()
            return Literal(line=t.line, column=t.column, kind=t.type.name, value=t.value)
        
        return self.parse_expr()
    
    def parse_expr(self):
        """Parse an expression."""
        return self.parse_logical_or()
    
    def parse_logical_or(self):
        """Parse logical OR expressions."""
        expr = self.parse_logical_and()
        
        while self.match(TokenType.OROR):
            op = self.previous()
            right = self.parse_logical_and()
            expr = BinaryOp(line=expr.line, column=expr.column, op="||", lhs=expr, rhs=right)
        
        return expr
    
    def parse_logical_and(self):
        """Parse logical AND expressions."""
        expr = self.parse_equality()
        
        while self.match(TokenType.ANDAND):
            op = self.previous()
            right = self.parse_equality()
            expr = BinaryOp(line=expr.line, column=expr.column, op="&&", lhs=expr, rhs=right)
        
        return expr
    
    def parse_equality(self):
        """Parse equality expressions."""
        expr = self.parse_comparison()
        
        while self.match(TokenType.EQEQ, TokenType.BANGEQ):
            op = self.previous()
            right = self.parse_comparison()
            expr = BinaryOp(line=expr.line, column=expr.column, 
                           op="==" if op.type == TokenType.EQEQ else "!=", 
                           lhs=expr, rhs=right)
        
        return expr
    
    def parse_comparison(self):
        """Parse comparison expressions."""
        expr = self.parse_addition()
        
        while self.match(TokenType.LT, TokenType.GT, TokenType.LTE, TokenType.GTE):
            op = self.previous()
            right = self.parse_addition()
            
            if op.type == TokenType.LT:
                op_str = "<"
            elif op.type == TokenType.GT:
                op_str = ">"
            elif op.type == TokenType.LTE:
                op_str = "<="
            else:
                op_str = ">="
                
            expr = BinaryOp(line=expr.line, column=expr.column, op=op_str, lhs=expr, rhs=right)
        
        return expr
    
    def parse_addition(self):
        """Parse addition and subtraction expressions."""
        expr = self.parse_multiplication()
        
        while self.match(TokenType.PLUS, TokenType.MINUS):
            op = self.previous()
            right = self.parse_multiplication()
            expr = BinaryOp(line=expr.line, column=expr.column, 
                           op="+" if op.type == TokenType.PLUS else "-", 
                           lhs=expr, rhs=right)
        
        return expr
    
    def parse_multiplication(self):
        """Parse multiplication, division, and modulo expressions."""
        expr = self.parse_unary()
        
        while self.match(TokenType.STAR, TokenType.SLASH, TokenType.PERCENT):
            op = self.previous()
            right = self.parse_unary()
            
            if op.type == TokenType.STAR:
                op_str = "*"
            elif op.type == TokenType.SLASH:
                op_str = "/"
            else:
                op_str = "%"
                
            expr = BinaryOp(line=expr.line, column=expr.column, op=op_str, lhs=expr, rhs=right)
        
        return expr
    
    def parse_unary(self):
        """Parse unary expressions."""
        if self.match(TokenType.BANG, TokenType.TILDE, TokenType.MINUS):
            op = self.previous()
            right = self.parse_unary()
            
            if op.type == TokenType.BANG:
                op_str = "!"
            elif op.type == TokenType.TILDE:
                op_str = "~"
            else:
                op_str = "u-"  # unary minus
                
            return UnaryOp(line=op.line, column=op.column, op=op_str, rhs=right)
        
        return self.parse_primary()
    
    def parse_primary(self):
        """Parse primary expressions (literals, identifiers, parenthesized expressions)."""
        token = self.peek()
        
        if token.type in (TokenType.INT, TokenType.HEX, TokenType.FLOAT, TokenType.DURATION, TokenType.STRING, TokenType.BOOL):
            t = self.advance()
            return Literal(line=t.line, column=t.column, kind=t.type.name, value=t.value)
        elif token.type == TokenType.DOLLAR_IDENT:
            return self.parse_dollar_identifier()
        elif token.type == TokenType.IDENT:
            t = self.advance()
            return Identifier(line=t.line, column=t.column, name=t.lexeme, is_dollar=False)
        elif token.type == TokenType.LPAREN:
            self.advance()
            expr = self.parse_expr()
            self.consume(TokenType.RPAREN, "Expected ')' after expression")
            return expr
        
        raise ParserError(f"Expected expression but got {token.type.name} at {token.line}:{token.column}")

# ---- Code Generator and IR Emitter ----
class ConstantPool:
    """Manages constant values in the IR."""
    def __init__(self):
        self.constants = []
        self.constant_index = {}  # For deduplication
    
    def add(self, kind: str, value: Any) -> int:
        """Add a constant to the pool and return its index."""
        key = (kind, self._get_hashable_value(value))
        
        if key in self.constant_index:
            return self.constant_index[key]
        
        index = len(self.constants)
        self.constants.append({"kind": kind, "value": value})
        self.constant_index[key] = index
        
        return index
    
    def _get_hashable_value(self, value: Any) -> Any:
        """Convert value to a hashable form for deduplication."""
        if isinstance(value, list):
            return tuple(value)
        return value
    
    def get_all(self) -> List[Dict[str, Any]]:
        """Return all constants."""
        return self.constants

class SymbolTable:
    """Manages function and label symbols in the IR."""
    def __init__(self):
        self.functions = {}  # name -> index
        self.labels = {}     # name -> offset
        self.capsules = {}   # name -> id
    
    def add_function(self, name: str) -> int:
        """Add a function name and return its index."""
        if name in self.functions:
            return self.functions[name]
        
        index = len(self.functions)
        self.functions[name] = index
        return index
    
    def add_label(self, name: str, offset: int) -> None:
        """Add a label and its bytecode offset."""
        self.labels[name] = offset
    
    def get_function_index(self, name: str) -> int:
        """Get the index of a function."""
        if name not in self.functions:
            self.add_function(name)
        return self.functions[name]
    
    def encode_capsule_id(self, name: str) -> int:
        """Encode a capsule name as a byte ID."""
        if name in self.capsules:
            return self.capsules[name]
        
        # Try to use hex names directly (A0, B7, etc)
        if len(name) == 2 and all(c in "0123456789ABCDEFabcdef" for c in name):
            capsule_id = int(name, 16) & 0xFF
        else:
            # Hash the name to get a stable ID
            capsule_id = self._hash_name(name) & 0xFF
        
        self.capsules[name] = capsule_id
        return capsule_id
    
    def _hash_name(self, name: str) -> int:
        """Simple hash function for capsule names."""
        h = 5381
        for c in name:
            h = ((h << 5) + h) + ord(c)
        return h & 0xFFFFFFFF

class CodeGenerator:
    """Generates bytecode from an AST."""
    def __init__(self, ast: Program):
        self.ast = ast
        self.bytecode = bytearray()
        self.const_pool = ConstantPool()
        self.symbols = SymbolTable()
        self.fixups = []  # (offset, type, target)
        self.loop_stack = []  # (break_offset, continue_offset)
    
    def generate(self) -> Tuple[bytearray, Dict[str, Any]]:
        """Generate bytecode and symbol information."""
        # Process entry block
        self.generate_block(self.ast.entry.block)
        
        # End the program
        self.emit(OPCODES["END"])
        
        # Process fixups
        self._process_fixups()
        
        # Return bytecode and symbol information
        return self.bytecode, {
            "constants": self.const_pool.get_all(),
            "functions": self.symbols.functions,
            "labels": self.symbols.labels,
            "capsules": self.symbols.capsules
        }
    
    def emit(self, *bytes_):
        """Emit one or more bytes to the bytecode."""
        for b in bytes_:
            self.bytecode.append(b & 0xFF)
    
    def emit_u16(self, value: int):
        """Emit a 16-bit value in little-endian format."""
        self.emit((value >> 8) & 0xFF, value & 0xFF)
    
    def current_offset(self) -> int:
        """Get the current bytecode offset."""
        return len(self.bytecode)
    
    def add_fixup(self, offset: int, type_: str, target: str):
        """Add a fixup record for later resolution."""
        self.fixups.append((offset, type_, target))
    
    def generate_block(self, block: Block):
        """Generate code for a block of statements."""
        for item in block.items:
            if isinstance(item, Decl):
                self.generate_declaration(item)
            else:
                self.generate_statement(item)
    
    def generate_declaration(self, decl: Decl):
        """Generate code for a declaration."""
        if isinstance(decl, LetDecl):
            # Let declarations don't generate code, just register the capsule
            self.symbols.encode_capsule_id(decl.name.name)
        elif isinstance(decl, FunctionDecl):
            # Register the function in the symbol table
            self.symbols.add_function(decl.name.name)
        elif isinstance(decl, WorkerDecl):
            # Register the worker in the symbol table
            self.symbols.add_function(decl.name.name)
        elif isinstance(decl, LabelStmt):
            # Define a label at the current bytecode offset
            self.symbols.add_label(decl.name, self.current_offset())
    
    def generate_statement(self, stmt: Stmt):
        """Generate code for a statement."""
        if isinstance(stmt, InitStmt):
            self.emit(OPCODES["INIT"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, LoadStmt):
            capsule_id = self.symbols.encode_capsule_id(stmt.target.name)
            const_idx = self.generate_value(stmt.value)
            self.emit(OPCODES["LOAD"], capsule_id)
            self.emit_u16(const_idx)
        
        elif isinstance(stmt, CallStmt):
            func_idx = self.symbols.get_function_index(stmt.func.name)
            if stmt.arg:
                capsule_id = self.symbols.encode_capsule_id(stmt.arg.name)
                self.emit(OPCODES["CALLA"])
                self.emit_u16(func_idx)
                self.emit(capsule_id)
            else:
                self.emit(OPCODES["CALL"])
                self.emit_u16(func_idx)
        
        elif isinstance(stmt, ExitStmt):
            self.emit(OPCODES["EXIT"])
        
        elif isinstance(stmt, LeaseStmt):
            self.emit(OPCODES["LEASE"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, SubleaseStmt):
            self.emit(OPCODES["SUBLEASE"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, ReleaseStmt):
            self.emit(OPCODES["RELEASE"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, CheckExpStmt):
            self.emit(OPCODES["CHECKEXP"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, RenderStmt):
            self.emit(OPCODES["RENDER"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, InputStmt):
            self.emit(OPCODES["INPUT"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, OutputStmt):
            self.emit(OPCODES["OUTPUT"], self.symbols.encode_capsule_id(stmt.target.name))
        
        elif isinstance(stmt, SendStmt):
            chan_id = self.symbols.encode_capsule_id(stmt.chan.name)
            pkt_id = self.symbols.encode_capsule_id(stmt.pkt.name)
            self.emit(OPCODES["SEND"], chan_id, pkt_id)
        
        elif isinstance(stmt, RecvStmt):
            chan_id = self.symbols.encode_capsule_id(stmt.chan.name)
            pkt_id = self.symbols.encode_capsule_id(stmt.pkt.name)
            self.emit(OPCODES["RECV"], chan_id, pkt_id)
        
        elif isinstance(stmt, SpawnStmt):
            func_idx = self.symbols.get_function_index(stmt.func.name)
            self.emit(OPCODES["SPAWN"])
            self.emit_u16(func_idx)
            self.emit(len(stmt.args))  # argc
            
            for arg in stmt.args:
                if isinstance(arg, Identifier) and arg.is_dollar:
                    # Capsule argument
                    self.emit(0x02, self.symbols.encode_capsule_id(arg.name))
                else:
                    # Constant argument
                    const_idx = self.generate_value(arg)
                    self.emit(0x01)  # kind = constant
                    self.emit_u16(const_idx)
        
        elif isinstance(stmt, JoinStmt):
            self.emit(OPCODES["JOIN"], self.symbols.encode_capsule_id(stmt.thread.name))
        
        elif isinstance(stmt, StampStmt):
            capsule_id = self.symbols.encode_capsule_id(stmt.target.name)
            const_idx = self.generate_value(stmt.value)
            self.emit(OPCODES["STAMP"], capsule_id)
            self.emit_u16(const_idx)
        
        elif isinstance(stmt, ExpireStmt):
            capsule_id = self.symbols.encode_capsule_id(stmt.target.name)
            const_idx = self.const_pool.add("DURATION", stmt.duration.value)
            self.emit(OPCODES["EXPIRE"], capsule_id)
            self.emit_u16(const_idx)
        
        elif isinstance(stmt, SleepStmt):
            const_idx = self.const_pool.add("DURATION", stmt.duration.value)
            self.emit(OPCODES["SLEEP"])
            self.emit_u16(const_idx)
        
        elif isinstance(stmt, YieldStmt):
            self.emit(OPCODES["YIELD"])
        
        elif isinstance(stmt, ErrorStmt):
            capsule_id = self.symbols.encode_capsule_id(stmt.target.name)
            code_idx = self.generate_value(stmt.code)
            msg_idx = self.const_pool.add("STRING", stmt.message.value)
            self.emit(OPCODES["ERROR"], capsule_id)
            self.emit_u16(code_idx)
            self.emit_u16(msg_idx)
        
        elif isinstance(stmt, IfStmt):
            # Generate condition
            self.generate_expr(stmt.cond)
            
            # Jump if false
            self.emit(OPCODES["JZ"])
            jz_offset = self.current_offset()
            self.emit_u16(0)  # Placeholder for jump offset
            
            # Generate then block
            self.generate_block(stmt.then_block)
            
            if stmt.else_block:
                # Jump to end after then block
                self.emit(OPCODES["JMP"])
                jmp_offset = self.current_offset()
                self.emit_u16(0)  # Placeholder for jump offset
                
                # Else block starts here
                else_offset = self.current_offset()
                
                # Patch the jz instruction to jump here
                self._patch_jump(jz_offset, else_offset)
                
                # Generate else block
                self.generate_block(stmt.else_block)
                
                # End of if statement
                end_offset = self.current_offset()
                
                # Patch the jmp instruction to jump here
                self._patch_jump(jmp_offset, end_offset)
            else:
                # No else block, end of if statement
                end_offset = self.current_offset()
                
                # Patch the jz instruction to jump here
                self._patch_jump(jz_offset, end_offset)
        
        elif isinstance(stmt, LoopStmt):
            # Save current loop context and create a new one
            loop_start = self.current_offset()
            
            # Generate condition
            self.generate_expr(stmt.cond)
            
            # Jump out of loop if condition is false
            self.emit(OPCODES["JZ"])
            loop_exit_offset = self.current_offset()
            self.emit_u16(0)  # Placeholder for jump offset
            
            # Save loop context for break/continue statements
            self.loop_stack.append((loop_exit_offset, loop_start))
            
            # Generate loop body
            self.generate_block(stmt.body)
            
            # Jump back to loop start
            self.emit(OPCODES["JMP"])
            self.emit_u16(loop_start - (self.current_offset() + 2))
            
            # Loop exit point
            loop_end = self.current_offset()
            
            # Patch the conditional jump
            self._patch_jump(loop_exit_offset, loop_end)
            
            # Restore previous loop context
            self.loop_stack.pop()
        
        elif isinstance(stmt, BreakStmt):
            if not self.loop_stack:
                raise RuntimeError("Break statement outside of loop")
            
            # Jump to the loop exit point
            loop_exit_offset = self.loop_stack[-1][0]
            self.emit(OPCODES["JMP"])
            
            # We don't know the exact jump target yet, so add a fixup
            fixup_offset = self.current_offset()
            self.emit_u16(0)  # Placeholder
            
            # Register a fixup to the loop exit
            self.add_fixup(fixup_offset, "loop_exit", str(loop_exit_offset))
        
        elif isinstance(stmt, ContinueStmt):
            if not self.loop_stack:
                raise RuntimeError("Continue statement outside of loop")
            
            # Jump to the loop start point
            loop_start = self.loop_stack[-1][1]
            self.emit(OPCODES["JMP"])
            self.emit_u16(loop_start - (self.current_offset() + 2))
        
        elif isinstance(stmt, GotoStmt):
            # Jump to the named label
            self.emit(OPCODES["JMP"])
            fixup_offset = self.current_offset()
            self.emit_u16(0)  # Placeholder
            
            # Add a fixup for this label
            self.add_fixup(fixup_offset, "label", stmt.label)
        
        else:
            raise NotImplementedError(f"Statement type {type(stmt).__name__} not implemented")
    
    def generate_expr(self, expr: Expr):
        """Generate code for an expression."""
        if isinstance(expr, Literal):
            # Push a constant onto the stack
            const_idx = self.const_pool.add(expr.kind, expr.value)
            self.emit(OPCODES["PUSHK"])
            self.emit_u16(const_idx)
        
        elif isinstance(expr, Identifier):
            if expr.is_dollar:
                # Push a capsule reference onto the stack
                self.emit(OPCODES["PUSHCAP"], self.symbols.encode_capsule_id(expr.name))
            else:
                # Push the identifier name as a string
                const_idx = self.const_pool.add("STRING", expr.name)
                self.emit(OPCODES["PUSHK"])
                self.emit_u16(const_idx)
        
        elif isinstance(expr, UnaryOp):
            # Generate the operand
            self.generate_expr(expr.rhs)
            
            # Apply the unary operator
            if expr.op in UNARY_OPS:
                self.emit(OPCODES["UNOP"], UNARY_OPS[expr.op])
            else:
                raise RuntimeError(f"Unknown unary operator: {expr.op}")
        
        elif isinstance(expr, BinaryOp):
            # Generate the left and right operands
            self.generate_expr(expr.lhs)
            self.generate_expr(expr.rhs)
            
            # Apply the binary operator
            if expr.op in BINARY_OPS:
                self.emit(OPCODES["BINOP"], BINARY_OPS[expr.op])
            else:
                raise RuntimeError(f"Unknown binary operator: {expr.op}")
        
        else:
            raise NotImplementedError(f"Expression type {type(expr).__name__} not implemented")
    
    def generate_value(self, value: Union[Expr, Literal, Identifier]) -> int:
        """Generate a value expression and return its constant index."""
        if isinstance(value, Literal):
            return self.const_pool.add(value.kind, value.value)
        
        elif isinstance(value, Identifier):
            if value.is_dollar:
                # Create a string representation of the capsule reference
                return self.const_pool.add("STRING", f"${value.name}")
            else:
                return self.const_pool.add("STRING", value.name)
        
        else:
            # For complex expressions, we need to generate evaluation code
            # Currently, we just convert them to strings
            return self.const_pool.add("STRING", "<expr>")
    
    def _patch_jump(self, offset: int, target: int):
        """Patch a jump instruction at the given offset to target the given address."""
        rel_offset = target - (offset + 2)  # +2 to account for the jump instruction's own size
        self.bytecode[offset] = (rel_offset >> 8) & 0xFF
        self.bytecode[offset + 1] = rel_offset & 0xFF
    
    def _process_fixups(self):
        """Process all pending fixups."""
        for offset, type_, target in self.fixups:
            if type_ == "label":
                if target not in self.symbols.labels:
                    raise RuntimeError(f"Undefined label: {target}")
                label_offset = self.symbols.labels[target]
                self._patch_jump(offset, label_offset)
            
            elif type_ == "loop_exit":
                # The target is the offset of the jz instruction's placeholder
                exit_offset = int(target)
                # Find the actual exit point (after the loop)
                actual_exit = self.current_offset()
                self._patch_jump(offset, actual_exit)
                
                # Also patch the original jz instruction
                self._patch_jump(exit_offset, actual_exit)

# ---- MSVC Integration and Optimizations ----
class MSVCIntegration:
    """Provides integration with Microsoft Visual Studio."""
    
    @staticmethod
    def generate_vs_project(output_dir: str, program_name: str, bytecode_path: str) -> str:
        """Generate a Visual Studio project for the compiled program."""
        # Create project directory
        project_dir = os.path.join(output_dir, f"{program_name}_vs_project")
        os.makedirs(project_dir, exist_ok=True)
        
        # Create a simple C++ runtime
        runtime_cpp = os.path.join(project_dir, "eminor_runtime.cpp")
        with open(runtime_cpp, "w") as f:
            f.write(MSVCIntegration._generate_runtime_cpp(program_name, bytecode_path))
        
        # Create a Visual Studio project file
        vcxproj_path = os.path.join(project_dir, f"{program_name}.vcxproj")
        with open(vcxproj_path, "w") as f:
            f.write(MSVCIntegration._generate_vcxproj(program_name))
        
        return project_dir
    
    @staticmethod
    def _generate_runtime_cpp(program_name: str, bytecode_path: str) -> str:
        """Generate a C++ runtime for the E Minor program."""
        with open(bytecode_path, "rb") as f:
            bytecode = f.read()
        
        bytecode_hex = ", ".join(f"0x{b:02X}" for b in bytecode)
        
        return f"""// E Minor Runtime for {program_name}
#include <iostream>
#include <fstream>
#include <vector>
#include <string>
#include <unordered_map>
#include <cstdint>

// Bytecode for the E Minor program
const uint8_t PROGRAM_BYTECODE[] = {{{bytecode_hex}}};
const size_t BYTECODE_SIZE = sizeof(PROGRAM_BYTECODE);

// E Minor VM
class EMinorVM {{
private:
    std::vector<uint8_t> bytecode;
    std::unordered_map<uint8_t, std::vector<uint8_t>> capsules;
    std::unordered_map<uint8_t, bool> leased_capsules;
    size_t pc = 0;
    
    // VM stack
    std::vector<int64_t> stack;
    
public:
    EMinorVM(const uint8_t* code, size_t size) {{
        bytecode.assign(code, code + size);
    }}
    
    void run() {{
        while (pc < bytecode.size()) {{
            uint8_t opcode = bytecode[pc++];
            
            switch (opcode) {{
                case 0x00: // NOP
                    break;
                    
                case 0x01: // INIT
                    {{
                        uint8_t capsule_id = bytecode[pc++];
                        capsules[capsule_id].clear();
                        std::cout << "Initialized capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                    }}
                    break;
                    
                case 0x05: // EXIT
                    std::cout << "Program exited" << std::endl;
                    return;
                    
                case 0x10: // LEASE
                    {{
                        uint8_t capsule_id = bytecode[pc++];
                        if (leased_capsules[capsule_id]) {{
                            std::cerr << "Error: Double lease on capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                        }}
                        leased_capsules[capsule_id] = true;
                        std::cout << "Leased capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                    }}
                    break;
                    
                case 0x11: // SUBLEASE
                    {{
                        uint8_t capsule_id = bytecode[pc++];
                        if (!leased_capsules[capsule_id]) {{
                            std::cerr << "Warning: Sublease on non-leased capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                        }}
                        std::cout << "Subleased capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                    }}
                    break;
                    
                case 0x12: // RELEASE
                    {{
                        uint8_t capsule_id = bytecode[pc++];
                        if (!leased_capsules[capsule_id]) {{
                            std::cerr << "Warning: Release on non-leased capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                        }}
                        leased_capsules[capsule_id] = false;
                        std::cout << "Released capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                    }}
                    break;
                    
                case 0x20: // RENDER
                    {{
                        uint8_t capsule_id = bytecode[pc++];
                        std::cout << "Rendered capsule 0x" << std::hex << (int)capsule_id << std::dec << std::endl;
                    }}
                    break;
                    
                case 0x52: // SLEEP
                    {{
                        uint16_t duration_idx = (bytecode[pc] << 8) | bytecode[pc+1];
                        pc += 2;
                        std::cout << "Sleep for " << duration_idx << " ns" << std::endl;
                    }}
                    break;
                    
                case 0x53: // YIELD
                    std::cout << "Yield" << std::endl;
                    break;
                    
                case 0xFF: // END
                    std::cout << "Program ended" << std::endl;
                    return;
                    
                default:
                    std::cerr << "Unknown opcode: 0x" << std::hex << (int)opcode << std::dec << std::endl;
                    return;
            }}
        }}
    }}
}};

int main() {{
    std::cout << "E Minor Runtime for {program_name}" << std::endl;
    
    EMinorVM vm(PROGRAM_BYTECODE, BYTECODE_SIZE);
    vm.run();
    
    return 0;
}}
"""
    
    @staticmethod
    def _generate_vcxproj(program_name: str) -> str:
        """Generate a Visual Studio project file."""
        return f"""<?xml version="1.0" encoding="utf-8"?>
<Project DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
  <ItemGroup Label="ProjectConfigurations">
    <ProjectConfiguration Include="Debug|Win32">
      <Configuration>Debug</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|Win32">
      <Configuration>Release</Configuration>
      <Platform>Win32</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Debug|x64">
      <Configuration>Debug</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
    <ProjectConfiguration Include="Release|x64">
      <Configuration>Release</Configuration>
      <Platform>x64</Platform>
    </ProjectConfiguration>
  </ItemGroup>
  <PropertyGroup Label="Globals">
    <VCProjectVersion>16.0</VCProjectVersion>
    <Keyword>Win32Proj</Keyword>
    <ProjectGuid>{{81a8cff0-b373-4551-a2ee-652a1a9a6f5e}}</ProjectGuid>
    <RootNamespace>{program_name}</RootNamespace>
    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\\Microsoft.Cpp.Default.props" />
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>true</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'" Label="Configuration">
    <ConfigurationType>Application</ConfigurationType>
    <UseDebugLibraries>false</UseDebugLibraries>
    <PlatformToolset>v143</PlatformToolset>
    <WholeProgramOptimization>true</WholeProgramOptimization>
    <CharacterSet>Unicode</CharacterSet>
  </PropertyGroup>
  <Import Project="$(VCTargetsPath)\\Microsoft.Cpp.props" />
  <ImportGroup Label="ExtensionSettings">
  </ImportGroup>
  <ImportGroup Label="Shared">
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <Import Project="$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <Import Project="$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <Import Project="$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <ImportGroup Label="PropertySheets" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <Import Project="$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
  </ImportGroup>
  <PropertyGroup Label="UserMacros" />
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|Win32'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>WIN32;NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>_DEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
    <ClCompile>
      <WarningLevel>Level3</WarningLevel>
      <FunctionLevelLinking>true</FunctionLevelLinking>
      <IntrinsicFunctions>true</IntrinsicFunctions>
      <SDLCheck>true</SDLCheck>
      <PreprocessorDefinitions>NDEBUG;_CONSOLE;%(PreprocessorDefinitions)</PreprocessorDefinitions>
      <ConformanceMode>true</ConformanceMode>
    </ClCompile>
    <Link>
      <SubSystem>Console</SubSystem>
      <EnableCOMDATFolding>true</EnableCOMDATFolding>
      <OptimizeReferences>true</OptimizeReferences>
      <GenerateDebugInformation>true</GenerateDebugInformation>
    </Link>
  </ItemDefinitionGroup>
  <ItemGroup>
    <ClCompile Include="eminor_runtime.cpp" />
  </ItemGroup>
  <Import Project="$(VCTargetsPath)\\Microsoft.Cpp.targets" />
  <ImportGroup Label="ExtensionTargets">
  </ImportGroup>
</Project>
"""

# ---- Optimizer ----
class Optimizer:
    """Optimizes E Minor bytecode."""
    
    @staticmethod
    def optimize(bytecode: bytearray, symbols: Dict[str, Any]) -> Tuple[bytearray, Dict[str, Any]]:
        """Apply optimizations to the bytecode."""
        # Apply peephole optimizations
        optimized = Optimizer._peephole_optimize(bytecode)
        
        # Constant folding
        optimized, symbols = Optimizer._fold_constants(optimized, symbols)
        
        # Dead code elimination
        optimized = Optimizer._eliminate_dead_code(optimized)
        
        return optimized, symbols
    
    @staticmethod
    def _peephole_optimize(bytecode: bytearray) -> bytearray:
        """Apply peephole optimizations."""
        result = bytearray()
        i = 0
        
        while i < len(bytecode):
            # Skip NOP instructions
            if bytecode[i] == OPCODES["NOP"]:
                i += 1
                continue
            
            # Optimize consecutive PUSHK/PUSHK/BINOP sequences (constant folding)
            if (i + 5 < len(bytecode) and
                bytecode[i] == OPCODES["PUSHK"] and
                bytecode[i+3] == OPCODES["PUSHK"] and
                bytecode[i+6] == OPCODES["BINOP"]):
                # We'll keep this pattern for now, but it could be optimized at a higher level
                pass
            
            # Copy the current instruction
            result.append(bytecode[i])
            i += 1
        
        return result
    
    @staticmethod
    def _fold_constants(bytecode: bytearray, symbols: Dict[str, Any]) -> Tuple[bytearray, Dict[str, Any]]:
        """Fold constant expressions."""
        # This would require more complex analysis
        return bytecode, symbols
    
    @staticmethod
    def _eliminate_dead_code(bytecode: bytearray) -> bytearray:
        """Eliminate dead code."""
        # Simple case: remove code after unconditional jumps
        result = bytearray()
        i = 0
        
        while i < len(bytecode):
            result.append(bytecode[i])
            
            if bytecode[i] == OPCODES["JMP"]:
                # Get jump offset
                offset = (bytecode[i+1] << 8) | bytecode[i+2]
                result.append(bytecode[i+1])
                result.append(bytecode[i+2])
                i += 3
                
                # If this is a forward jump and not a loop, we can skip code until the target
                if offset > 0:
                    target = i + offset
                    # But we need to be careful about not skipping important instructions
                    # For now, we'll only skip if we're jumping to the end or to a label
                    if target >= len(bytecode) - 1 or bytecode[target] == OPCODES["END"]:
                        # Skip everything until the target
                        i = target
                        continue
            else:
                i += 1
        
        return result

# ---- Compiler extensions for file handling ----
def compile_file(source_path: str, output_dir: str = None, optimize: bool = True, 
                 generate_vs_project: bool = False) -> Dict[str, Any]:
    """Compile an E Minor source file."""
    if output_dir is None:
        output_dir = os.path.dirname(source_path) or "."
    
    base_name = os.path.splitext(os.path.basename(source_path))[0]
    
    # Read source file
    with open(source_path, "r", encoding="utf-8") as f:
        source = f.read()
    
    # Lex
    lexer = Lexer(source)
    try:
        tokens = lexer.tokenize()
    except LexerError as e:
        return {"success": False, "stage": "lexer", "error": str(e)}
    
    # Parse
    parser = Parser(tokens)
    try:
        ast = parser.parse()
    except ParserError as e:
        return {"success": False, "stage": "parser", "error": str(e)}
    
    # Validate
    issues = validate(ast)
    has_errors = any(issue["severity"] == "ERROR" for issue in issues)
    
    if has_errors:
        return {
            "success": False, 
            "stage": "validator",
            "error": "Validation errors found",
            "issues": issues
        }
    
    # Generate code
    generator = CodeGenerator(ast)
    bytecode, symbols = generator.generate()
    
    # Optimize if requested
    if optimize:
        bytecode, symbols = Optimizer.optimize(bytecode, symbols)
    
    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Write output files
    ir_hex_path = os.path.join(output_dir, f"{base_name}.ir.hex")
    ir_bin_path = os.path.join(output_dir, f"{base_name}.ir.bin")
    sym_path = os.path.join(output_dir, f"{base_name}.sym.json")
    
    # Write hex output
    with open(ir_hex_path, "w") as f:
        f.write(" ".join(f"{b:02X}" for b in bytecode))
    
    # Write binary output
    with open(ir_bin_path, "wb") as f:
        f.write(bytecode)
    
    # Write symbol information
    with open(sym_path, "w") as f:
        json.dump(symbols, f, indent=2)
    
    # Generate Visual Studio project if requested
    vs_project_path = None
    if generate_vs_project:
        vs_project_path = MSVCIntegration.generate_vs_project(output_dir, base_name, ir_bin_path)
    
    # Save validation issues for reference (even if only warnings)
    if issues:
        issues_path = os.path.join(output_dir, f"{base_name}.issues.json")
        with open(issues_path, "w") as f:
            json.dump({"issues": issues}, f, indent=2)
    
    return {
        "success": True,
        "ir_hex_path": ir_hex_path,
        "ir_bin_path": ir_bin_path,
        "sym_path": sym_path,
        "vs_project_path": vs_project_path,
        "issues": issues
    }

def compiler_main():
    """Main entry point for the E Minor compiler."""
    parser = argparse.ArgumentParser(description="E Minor Compiler v1.0")
    parser.add_argument("source", help="E Minor source file to compile")
    parser.add_argument("-o", "--output-dir", help="Output directory for compiled files")
    parser.add_argument("--no-optimize", action="store_true", help="Disable bytecode optimizations")
    parser.add_argument("--validate-only", action="store_true", help="Only validate, don't generate code")
    parser.add_argument("--vs-project", action="store_true", help="Generate Visual Studio project")
    
    args = parser.parse_args()
    
    if args.validate_only:
        # Read source file
        with open(args.source, "r", encoding="utf-8") as f:
            source = f.read()
        
        # Lex and parse
        lexer = Lexer(source)
        tokens = lexer.tokenize()
        parser = Parser(tokens)
        ast = parser.parse()
        
        # Validate
        issues = validate(ast)
        print(json.dumps({"issues": issues}, indent=2))
        
        has_errors = any(issue["severity"] == "ERROR" for issue in issues)
        if has_errors:
            print("Validation failed with errors.")
            sys.exit(1)
        else:
            print("Validation successful (may have warnings).")
            sys.exit(0)
    
    # Full compilation
    result = compile_file(
        args.source, 
        args.output_dir, 
        not args.no_optimize,
        args.vs_project
    )
    
    if not result["success"]:
        print(f"Compilation failed during {result['stage']}: {result['error']}")
        if "issues" in result:
            print(json.dumps({"issues": result["issues"]}, indent=2))
        sys.exit(1)
    
    print(f"Compilation successful:")
    print(f"  IR Hex: {result['ir_hex_path']}")
    print(f"  IR Bin: {result['ir_bin_path']}")
    print(f"  Symbols: {result['sym_path']}")
    
    if result.get("vs_project_path"):
        print(f"  VS Project: {result['vs_project_path']}")
    
    if result["issues"]:
        print(f"  Warnings: {len(result['issues'])} issues found (see output for details)")

if __name__ == "__main__":
    # Use compiler_main() when invoked as a compiler
    if len(sys.argv) > 1 and not sys.argv[1].endswith('.json'):
        compiler_main()
    else:
        # Original validation-only behavior
        main()
